import os
import cv2
import torch
import numpy as np
from tqdm import tqdm
from wilor_mini.pipelines.wilor_hand_pose3d_estimation_pipeline import WiLorHandPose3dEstimationPipeline
import re
from pathlib import Path

def natural_sort_key(s):
    """
    ìì—° ì •ë ¬ì„ ìœ„í•œ í‚¤ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    ì˜ˆ: "frame10.jpg"ëŠ” "frame2.jpg"ë³´ë‹¤ ë’¤ì— ì˜¤ë„ë¡ ì •ë ¬í•©ë‹ˆë‹¤.
    """
    return [int(text) if text.isdigit() else text.lower()
            for text in re.split(r'(\d+)', str(s))]

def process_dataset_and_save_trajectories():
    """
    ì§€ì •ëœ ê¸°ë³¸ í´ë” ë‚´ì˜ ëª¨ë“  ì•¡ì…˜ì— ëŒ€í•´ ì† ê¶¤ì ì„ ì¶”ì¶œí•˜ê³  .npy íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    # --- âš™ï¸ ì‚¬ìš©ì ì„¤ì • ì˜ì—­ âš™ï¸ ---
    base_input_folder = "/media/kcy/3A72CA7272CA3285/data_MHAV"
    track_hand = 'right'  # ì¶”ì í•  ì†: 'right' ë˜ëŠ” 'left'
    num_frames = 500      # ì €ì¥í•  ìµœì¢… í”„ë ˆì„ ìˆ˜
    # ------------------------------------

    # 1. ëª¨ë¸ ì´ˆê¸°í™”
    print("ğŸš€ WILOR ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    # WiLoR-miniëŠ” float32ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    pipe = WiLorHandPose3dEstimationPipeline(device=device, dtype=torch.float32, verbose=False)
    print(f"âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ. ({device} ì‚¬ìš©)")

    # 2. ì²˜ë¦¬í•  ì•¡ì…˜ í´ë” ëª©ë¡ íƒìƒ‰
    # ê° ì•¡ì…˜ì˜ 'RGB_undistorted' í´ë”ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    try:
        image_folders = sorted(Path(base_input_folder).glob('**/RGB_undistorted'))
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: ìµœìƒìœ„ ì…ë ¥ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_input_folder}")
        return

    if not image_folders:
        print(f"âŒ ì˜¤ë¥˜: '{base_input_folder}' ì•ˆì—ì„œ 'RGB_undistorted' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nì´ {len(image_folders)}ê°œì˜ ì•¡ì…˜ í´ë”ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # 3. ê° ì•¡ì…˜ í´ë”ë³„ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    for image_folder in tqdm(image_folders, desc="ì „ì²´ ì•¡ì…˜ ì§„í–‰ë¥ "):
        action_folder = image_folder.parent
        action_name = f"{action_folder.parent.name}_{action_folder.name}"
        tqdm.write("-" * 70)
        tqdm.write(f"Processing action: {action_name}")

        image_paths = sorted(image_folder.glob('*.png'), key=natural_sort_key)
        if not image_paths:
            image_paths = sorted(image_folder.glob('*.jpg'), key=natural_sort_key)
        
        if not image_paths:
            tqdm.write(f"âš ï¸ ê²½ê³ : '{action_name}'ì— ì´ë¯¸ì§€ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        
        # ê° ì•¡ì…˜ì˜ ì†ëª© ì¢Œí‘œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        hand_path_points = []
        for img_path in tqdm(image_paths, desc=f"Pose Estimation ({action_name})", leave=False):
            image = cv2.imread(str(img_path))
            if image is None:
                continue

            # WiLoRë¡œ ì† ì˜ˆì¸¡ (cv2ë¡œ ì½ì€ BGR í”„ë ˆì„ ì§ì ‘ ì‚¬ìš©)
            outputs = pipe.predict(image)
            
            target_hand_output = None
            if outputs:
                for out in outputs:
                    if (track_hand == 'right' and out['is_right'] == 1) or \
                       (track_hand == 'left' and out['is_right'] == 0):
                        target_hand_output = out
                        break
            
            if target_hand_output:
                wrist_keypoint_2d = target_hand_output["wilor_preds"]["pred_keypoints_2d"][0][0]
                center_x, center_y = int(wrist_keypoint_2d[0]), int(wrist_keypoint_2d[1])
                hand_path_points.append([center_x, center_y])

        # --- NPY íŒŒì¼ ì €ì¥ ë¡œì§ ---
        if not hand_path_points:
            tqdm.write(f"âš ï¸ ê²½ê³ : '{action_name}'ì—ì„œ ì†ì´ ì „í˜€ ê°ì§€ë˜ì§€ ì•Šì•„ .npy íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            continue

        total_detected_frames = len(hand_path_points)
        points_to_process = np.array(hand_path_points, dtype=np.float32)
        final_path_array = None

        if total_detected_frames >= num_frames:
            # ì¤‘ì•™ì—ì„œ num_frames ë§Œí¼ ìë¥´ê¸°
            start_index = (total_detected_frames - num_frames) // 2
            end_index = start_index + num_frames
            final_path_array = points_to_process[start_index:end_index]
        else:
            # ë¶€ì¡±í•œ ë§Œí¼ ë’·ë¶€ë¶„ì„ ë§ˆì§€ë§‰ ì¢Œí‘œë¡œ ì±„ìš°ê¸°
            padding_needed = num_frames - total_detected_frames
            last_coordinate = points_to_process[-1]
            back_padding = np.tile(last_coordinate, (padding_needed, 1))
            final_path_array = np.concatenate([points_to_process, back_padding], axis=0)
        
        # .npy íŒŒì¼ ì €ì¥ (ì•¡ì…˜ í´ë” ë‚´ì— ì €ì¥)
        output_filename = f"{action_name}_wrist_trajectory.npy"
        output_path = action_folder / output_filename
        np.save(output_path, final_path_array)
        tqdm.write(f"âœ… ê¶¤ì  ì¶”ì¶œ ì™„ë£Œ ë° ì €ì¥: {output_path}")
        tqdm.write(f"   (ê°ì§€ëœ í”„ë ˆì„: {total_detected_frames}, ì €ì¥ëœ í˜•íƒœ: {final_path_array.shape})")

    print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == '__main__':
    process_dataset_and_save_trajectories()